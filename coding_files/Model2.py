# -*- coding: utf-8 -*-
"""Best_Model_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FTUS6e377SDR8IfwZAZo7UN9h_BDk0uo
"""

pip install ta

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import TimeSeriesSplit
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE
import xgboost as xgb
import os
import yfinance as yf
import ta

"""### Data Loading and Preprocessing"""

# Load the dataset
file_path = 'nasdaq.csv'
nasdaq_data = pd.read_csv(file_path)

#Remove unwanted cols
del nasdaq_data['Unnamed: 0']

nasdaq_data.head(15)

"""#### Feature Engineering"""

# Create a target variable for classification (1 day ahead)
# Here we have taken a 2% change for the target variable (>2: Up, <2: down, else neutral)
def classify_target(row):
    change = (row['Close_1_days_ahead'] - row['Close']) / row['Close']
    if change > 0.02:
        return 1  # Up
    elif change < -0.02:
        return 0  # Down
    else:
        return 2  # Neutral

nasdaq_data['Close_1_days_ahead'] = nasdaq_data['Close'].shift(-1)
nasdaq_data['Target'] = nasdaq_data.apply(classify_target, axis=1)
nasdaq_data = nasdaq_data[:-1]  # Remove the last 1 row with NaN target

nasdaq_data.head(15)

nasdaq_data.tail(3)

nasdaq_data['Target'].unique()

nasdaq_data['Target'].value_counts()

# Add moving averages
nasdaq_data['MA10'] = nasdaq_data['Close'].rolling(window=10).mean()
nasdaq_data['MA50'] = nasdaq_data['Close'].rolling(window=10).mean()
nasdaq_data['MA200'] = nasdaq_data['Close'].rolling(window=10).mean()
#Measures volatility and can indicate potential overbought or oversold conditions
#Compares a particular closing price of a security to a range of its prices over a certain period.
nasdaq_data['BB_upper'], nasdaq_data['BB_middle'], nasdaq_data['BB_lower'] = ta.volatility.BollingerBands(nasdaq_data['Close']).bollinger_hband(), ta.volatility.BollingerBands(nasdaq_data['Close']).bollinger_mavg(), ta.volatility.BollingerBands(nasdaq_data['Close']).bollinger_lband()
nasdaq_data['Stochastic'] = ta.momentum.StochasticOscillator(nasdaq_data['High'], nasdaq_data['Low'], nasdaq_data['Close']).stoch()

nasdaq_data.dropna(inplace=True)  # Drop rows with NaN values

# Select features based on correlation
features = ['RSI', 'MACD_Signal', 'MACD', 'Volume', 'MA10', 'MA50', 'MA200', 'BB_upper', 'BB_middle', 'BB_lower', 'Stochastic']

# Features and target
X = nasdaq_data[features]
y = nasdaq_data['Target']

# Scale the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Define classifiers to compare for best model selection
classifiers = {
    'GradientBoosting': GradientBoostingClassifier(random_state=42),
    'RandomForest': RandomForestClassifier(random_state=42, class_weight='balanced'),
    'AdaBoost': AdaBoostClassifier(random_state=42),
    'LogisticRegression': LogisticRegression(random_state=42, max_iter=10000, class_weight='balanced'),
    'SVM': SVC(random_state=42, class_weight='balanced'),
    'XGBoost': xgb.XGBClassifier(random_state=42, scale_pos_weight=len(y)/sum(y == 1))
}

# Use TimeSeriesSplit for time series cross-validation
tscv = TimeSeriesSplit(n_splits=5)

# Compare classifiers using time series cross-validation
best_classifier = None
best_score = 0
results = {}

for name, clf in classifiers.items():
    scores = []
    for train_index, test_index in tscv.split(X_scaled):
        # Convert train and test indices to lists
        train_index = list(train_index)
        test_index = list(test_index)

        X_train, X_test = X_scaled[train_index], X_scaled[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # Oversample the minority classes (0 and 1) in the training set
        smote = SMOTE(random_state=42)
        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

        clf.fit(X_train_resampled, y_train_resampled)
        y_pred = clf.predict(X_test)
        scores.append(accuracy_score(y_test, y_pred))

    avg_score = np.mean(scores)
    results[name] = avg_score
    if avg_score > best_score:
        best_score = avg_score
        best_classifier = clf

# # Compare classifiers
# best_classifier = None
# best_score = 0
# results = {}

# for name, clf in classifiers.items():
#     scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')
#     avg_score = scores.mean()
#     results[name] = avg_score
#     if avg_score > best_score:
#         best_score = avg_score
#         best_classifier = clf

# Print results
print("\nModels & Accuracies:\n")
for name, score in results.items():
    print(f"{name}: {score:.4f}")

print(f"\nBest Classifier: {best_classifier.__class__.__name__} with score: {best_score:.4f}")

# Train the best classifier on the full training set
train_index, test_index = list(tscv.split(X_scaled))[-1]
X_train, X_test = X_scaled[train_index], X_scaled[test_index]
y_train, y_test = y.iloc[train_index], y.iloc[test_index]

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

best_classifier.fit(X_train_resampled, y_train_resampled)

# Predict the model on the last split
y_pred = best_classifier.predict(X_test)

# Evaluate the model
classification_report_result = classification_report(y_test, y_pred)
confusion_matrix_result = confusion_matrix(y_test, y_pred)
accuracy_result = accuracy_score(y_test, y_pred)

# Print the evaluation metrics
print("\nClassification Report:\n", classification_report_result)
print("Confusion Matrix:\n", confusion_matrix_result)
print("Accuracy Score:", accuracy_result)

# Visualize the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=['Down', 'Up', 'Neutral'], yticklabels=['Down', 'Up', 'Neutral'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Make predictions for the entire dataset
nasdaq_data['Predicted'] = best_classifier.predict(scaler.transform(nasdaq_data[features]))

nasdaq_data.head(15)

# Predict the market trend for the next day
next_days_predictions = []
next_days_prices = []
current_features = nasdaq_data[features].iloc[-1]
current_price = nasdaq_data['Close'].iloc[-1]

# Predict for 1 day
prediction = best_classifier.predict(scaler.transform([current_features]))[0]

# Update the price based on the prediction
if prediction == 1:
    next_price = current_price * 1.02  # Assuming a 2% increase
elif prediction == 0:
    next_price = current_price * 0.98  # Assuming a 2% decrease
else:
    next_price = current_price  # No change for neutral

next_days_prices.append(next_price)
current_price = next_price

# Print the predictions for next day
print("Predictions for the next day: ", ["Up" if prediction == 1 else "Down" if prediction == 0 else "Neutral"])
print("Predicted price for the next day: ", next_days_prices)



# Plot the actual market trend and the predicted trend for the next days

nasdaq_data['Date'] = pd.to_datetime(nasdaq_data['Date'])
plt.figure(figsize=(14, 7))
plt.plot(nasdaq_data['Date'], nasdaq_data['Close'], label='Actual Close Price', color='blue')
plt.axvline(x=nasdaq_data['Date'].iloc[-1], color='gray', linestyle='--')

last_date = nasdaq_data['Date'].iloc[-1]
date = pd.to_datetime(last_date) + pd.DateOffset(days=1)  # Compute the next date
close_price = nasdaq_data['Close'].iloc[-1]
color = 'green' if prediction == 1 else 'red' if prediction == 0 else 'yellow'
plt.plot(date, close_price, marker='o', color=color, markersize=10,
         label=f'Next Day {"Up" if prediction == 1 else "Down" if prediction == 0 else "Neutral"}')

plt.xlabel('Date')
plt.ylabel('Close Price')
plt.title('Market Trend with Next Day Predictions')
plt.legend()
plt.grid(True)
plt.show()

# Time series plot for EMA 50 and 200 with closing price
plt.figure(figsize=(14, 7))
plt.plot(nasdaq_data['Date'], nasdaq_data['Close'], label='Close Price')
plt.plot(nasdaq_data['Date'], nasdaq_data['EMA_50'], label='EMA 50')
plt.plot(nasdaq_data['Date'], nasdaq_data['EMA_200'], label='EMA 200')
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Stock Price with EMA')
plt.legend()
plt.show()

# RSI and MACD plot
fig, ax = plt.subplots(2, 1, figsize=(14, 10), sharex=True)
ax[0].plot(nasdaq_data['Date'], nasdaq_data['RSI'], label='RSI')
ax[0].axhline(70, color='r', linestyle='--')
ax[0].axhline(30, color='r', linestyle='--')
ax[0].set_ylabel('RSI')
ax[0].legend()

ax[1].plot(nasdaq_data['Date'], nasdaq_data['MACD'], label='MACD')
ax[1].plot(nasdaq_data['Date'], nasdaq_data['MACD_Signal'], label='MACD Signal')
ax[1].bar(nasdaq_data['Date'], nasdaq_data['MACD_Hist'], label='MACD Hist')
ax[1].set_xlabel('Date')
ax[1].set_ylabel('MACD')
ax[1].legend()

plt.show()

"""1) The first plot is a graph of the Relative Strength Index (RSI) for NASDAQ from 1990 to 2024. The RSI is a momentum oscillator that measures the speed and change of price movements. It is used by traders to identify overbought or oversold conditions in a market. When the RSI is above 70 (the upper red dashed line), it suggests that the market may be overbought, and a downward correction in price could be forthcoming. Conversely, when the RSI is below 30 (the lower red dashed line), it indicates that the market may be oversold, and an upward correction could be expected.

2) The second plot shows the Moving Average Convergence Divergence (MACD) for the same period. The MACD is a trend-following momentum indicator that shows the relationship between two moving averages of a securityâ€™s price. The MACD line (blue) is the difference between a short-term and a long-term moving average. The MACD Signal line (orange) is a moving average of the MACD line. When the MACD line crosses above the Signal line, it generates a bullish signal, indicating that it may be an optimal time to buy. Conversely, when the MACD line crosses below the Signal line, it generates a bearish signal, suggesting that it might be an optimal time to sell. The MACD Histogram (vertical bars) represents the difference between the MACD line and the Signal line, which can provide additional insights into the bullish or bearish momentum in the market.
"""

print(f'Y Test:\n{y_test}')

print(f'Y Pred:\n{y_pred}')

import numpy as np

# Select a subset of the data for clearer visualization
subset_size = 20
subset_indices = np.random.choice(len(y_test), subset_size, replace=False)
subset_actual = y_test.iloc[subset_indices]
subset_predicted = y_pred[subset_indices]

x = np.arange(subset_size)  # the label locations
width = 0.35  # the width of the bars

fig, ax = plt.subplots(figsize=(14, 7))
rects1 = ax.bar(x - width/2, subset_actual, width, label='Actual')
rects2 = ax.bar(x + width/2, subset_predicted, width, label='Predicted')

ax.set_xlabel('Samples')
ax.set_ylabel('Target')
ax.set_title('Actual vs Predicted for a Subset of Samples')
ax.set_xticks(x)
ax.legend()

fig.tight_layout()
plt.show()

pip install lime

import lime
import lime.lime_tabular

# Create LIME explainer
explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data=X_train_resampled,
    feature_names=features,
    class_names=['Down', 'Up', 'Neutral'],
    mode='classification'
)

# Select a sample for explanation
sample_index = 10  # Adjust index as needed to choose a sample
sample = X_test[sample_index]

# Generate explanation for the selected sample
exp = explainer.explain_instance(sample, best_classifier.predict_proba, num_features=len(features))

# Display the explanation
exp.show_in_notebook(show_table=True)

from datetime import datetime
import os
import pandas as pd
import yfinance as yf

# Load or fetch NASDAQ data
if os.path.exists("nasdaq_new.csv"):
    nasdaq_new = pd.read_csv("nasdaq_new.csv")
else:
    nasdaq_new = yf.Ticker("^IXIC")
    nasdaq_new = nasdaq_new.history(period="max")
    nasdaq_new.to_csv("nasdaq_new.csv")

nasdaq_new.head()

# Technical indicators
# Calculate technical indicators
print("Calculating technical indicators...")
nasdaq_new['EMA_50'] = ta.trend.ema_indicator(nasdaq_new['Close'], window=50)
nasdaq_new['EMA_200'] = ta.trend.ema_indicator(nasdaq_new['Close'], window=200)
nasdaq_new['RSI'] = ta.momentum.rsi(nasdaq_new['Close'])
macd = ta.trend.MACD(nasdaq_new['Close'])
nasdaq_new['MACD'] = macd.macd()
nasdaq_new['MACD_Signal'] = macd.macd_signal()
nasdaq_new['MACD_Hist'] = macd.macd_diff()

# Add moving averages
nasdaq_new['MA10'] = nasdaq_new['Close'].rolling(window=10).mean()
nasdaq_new['MA50'] = nasdaq_new['Close'].rolling(window=10).mean()
nasdaq_new['MA200'] = nasdaq_new['Close'].rolling(window=10).mean()

# Measures volatility and can indicate potential overbought or oversold conditions
# Compares a particular closing price of a security to a range of its prices over a certain period.
nasdaq_new['BB_upper'], nasdaq_new['BB_middle'], nasdaq_new['BB_lower'] = ta.volatility.BollingerBands(nasdaq_new['Close']).bollinger_hband(), ta.volatility.BollingerBands(nasdaq_new['Close']).bollinger_mavg(), ta.volatility.BollingerBands(nasdaq_new['Close']).bollinger_lband()

nasdaq_new['Stochastic'] = ta.momentum.StochasticOscillator(nasdaq_new['High'], nasdaq_new['Low'], nasdaq_new['Close']).stoch()

nasdaq_new.dropna(inplace=True)  # Drop rows with NaN values

# Removing the unwanted columns
del nasdaq_new['Dividends']
del nasdaq_new['Stock Splits']

nasdaq_new.tail(3)

# Filter the data starting from 2024-07-11
nasdaq_new.reset_index(inplace=True)  # Reset the index to access 'Date' column
nasdaq_new['Date'] = pd.to_datetime(nasdaq_new['Date'], utc=True)

nasdaq_new = nasdaq_new[nasdaq_new['Date'] > '2024-07-11']

nasdaq_new.head()

#save the latest file
nasdaq_new.to_csv("nasdaq_new.csv")

#Creating a target variable/column for predictions
# nasdaq_new['Close_1_days_ahead'] = nasdaq_new['Close'].shift(-1)
nasdaq_new['Target'] = nasdaq_new.apply(classify_target, axis=1)
nasdaq_new = nasdaq_new[:-1]  # Remove the last 1 row with NaN target

nasdaq_new.head(3)

# Step 2: Load and preprocess the new data
new_data = pd.read_csv('nasdaq_new.csv')
# Select features based on correlation
features = ['RSI', 'MACD_Signal', 'MACD', 'Volume', 'MA10', 'MA50', 'MA200', 'BB_upper', 'BB_middle', 'BB_lower', 'Stochastic']

# Features and target
X_new = nasdaq_new[features]

X_new_scaled = scaler.transform(X_new)

# Step 3: Make predictions on the new data
y_new_pred = best_classifier.predict(X_new_scaled)
y_new_prob = best_classifier.predict_proba(X_new_scaled)

# Print the predictions
y_new_actual = nasdaq_new['Target']
y_new_actual = y_new_actual.tolist()
print("Predictions on new data:", y_new_actual)

# Print the predictions
y_new_pred = y_new_pred.tolist()
print("Predictions on new data:", y_new_pred)

# Evaluate the model
accuracy_result = accuracy_score(y_new_actual, y_new_pred)

# Print the evaluation metrics
print("Accuracy Score:", accuracy_result)

# Assuming you have y_new_actual and y_new_pred lists
plt.figure(figsize=(10, 6))
plt.scatter(range(len(y_new_actual)), y_new_actual, label='Actual', color='blue', marker='o')
plt.scatter(range(len(y_new_pred)), y_new_pred, label='Predicted', color='red', marker='x')
plt.xlabel('Index')
plt.ylabel('Target Value')
plt.title('Actual vs Predicted Values')
plt.legend()
plt.show()